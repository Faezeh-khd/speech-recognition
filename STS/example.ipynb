{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example pipeline\n",
    "\n",
    "import speech_recognition as sr\n",
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "\n",
    "# Step 1: Speech Recognition\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Speak something...\")\n",
    "    audio = recognizer.listen(source)\n",
    "    source_text = recognizer.recognize_google(audio)\n",
    "\n",
    "# Step 2: Translation\n",
    "translator = Translator()\n",
    "target_text = translator.translate(source_text, src='en', dest='es').text\n",
    "\n",
    "# Step 3: Text-to-Speech\n",
    "tts = gTTS(target_text, lang='es')\n",
    "tts.save(\"output.mp3\")\n",
    "\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"output.mp3\")\n",
    "pygame.mixer.music.play()\n",
    "while pygame.mixer.music.get_busy():\n",
    "    continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creating an end-to-end speech-to-speech (S2S) model is more complex than the pipeline-based approach due to the deep learning models required for processing audio directly. Below is a simple prototype for an end-to-end speech-to-speech translation system, using libraries like Whisper (for ASR), Google Translate API (for translation), and Coqui TTS (for TTS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install whisper coqui-tts googletrans==4.0.0-rc1 pyaudio\n",
    "\n",
    "import whisper\n",
    "from googletrans import Translator\n",
    "from TTS.api import TTS\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "\n",
    "# Step 1: Record Audio\n",
    "def record_audio(filename=\"input.wav\", duration=5):\n",
    "    print(\"Recording...\")\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 1\n",
    "    rate = 44100  # Sample rate\n",
    "\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "    stream = p.open(format=sample_format, channels=channels,\n",
    "                    rate=rate, input=True, frames_per_buffer=chunk)\n",
    "    frames = []\n",
    "\n",
    "    # Record for the specified duration\n",
    "    for _ in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recorded audio\n",
    "    wf = wave.open(filename, \"wb\")\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b\"\".join(frames))\n",
    "    wf.close()\n",
    "    print(\"Recording complete.\")\n",
    "\n",
    "# Step 2: Transcribe Speech\n",
    "def transcribe_audio(filename=\"input.wav\"):\n",
    "    print(\"Transcribing...\")\n",
    "    model = whisper.load_model(\"base\")  # Whisper model\n",
    "    result = model.transcribe(filename)\n",
    "    print(\"Transcription:\", result[\"text\"])\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Step 3: Translate Text\n",
    "def translate_text(text, src_lang=\"en\", target_lang=\"es\"):\n",
    "    print(\"Translating...\")\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src=src_lang, dest=target_lang)\n",
    "    print(\"Translation:\", translation.text)\n",
    "    return translation.text\n",
    "\n",
    "# Step 4: Synthesize Speech\n",
    "def synthesize_speech(text, lang=\"es\", output_file=\"output.wav\"):\n",
    "    print(\"Synthesizing speech...\")\n",
    "    tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\")\n",
    "    tts.tts_to_file(text=text, file_path=output_file)\n",
    "    print(f\"Audio saved to {output_file}\")\n",
    "\n",
    "# Step 5: Play Audio\n",
    "def play_audio(filename=\"output.wav\"):\n",
    "    print(\"Playing audio...\")\n",
    "    os.system(f\"start {filename}\")  # For Windows\n",
    "    # Use `open` for macOS or `xdg-open` for Linux\n",
    "\n",
    "# Main Function\n",
    "if __name__ == \"__main__\":\n",
    "    # Record audio from the microphone\n",
    "    record_audio()\n",
    "\n",
    "    # Transcribe speech to text\n",
    "    source_text = transcribe_audio()\n",
    "\n",
    "    # Translate the transcribed text\n",
    "    translated_text = translate_text(source_text, src_lang=\"en\", target_lang=\"es\")\n",
    "\n",
    "    # Synthesize speech from the translated text\n",
    "    synthesize_speech(translated_text, lang=\"es\")\n",
    "\n",
    "    # Play the synthesized audio\n",
    "    play_audio()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
